AMD RYZEN AI 400 SERIES & AI MAX+ EXPANSION AT CES 2026
Product Launch | AMD | January 7, 2026

AMD announced a comprehensive portfolio expansion at CES 2026, introducing the Ryzen AI 400 Series for mainstream AI PCs and expanding the Ryzen AI Max+ Series with unprecedented memory allocation capabilities for integrated graphics.

RYZEN AI 400 SERIES (Mainstream AI PCs):

Performance:
- Up to 60 TOPS NPU performance
- CPU frequency up to 5.2GHz
- Memory speed: Up to 8,533 MT/s (vs. 8,000 MT/s previous gen)
- Microsoft Copilot+ PC certified

Availability:
- Laptops: March 2026
- Desktop variants: TBD

Target Market:
- Consumer AI PCs
- Business laptops (Ryzen AI PRO 400 Series variant)
- Small form factor devices

RYZEN AI MAX+ SERIES (High-Performance):

New Models:
- 8-core and 12-core variants
- Up to 60 teraflops performance
- 40 GPU cores (integrated RDNA 3.5 graphics)

**CRITICAL FEATURE: Dynamic Memory Allocation**
- **Up to 128GB of system memory allocatable to integrated GPU**
- Enables running large AI models without discrete GPU
- Unified memory architecture (similar to Apple's approach)

Use Cases:
- Local LLM inference (70B+ models)
- AI model training and fine-tuning
- Content creation with AI-enhanced workflows
- Multi-agent AI systems

RYZEN AI HALO (Developer Platform):

AMD introduced "Ryzen AI Halo," its first AMD-branded AI developer platform:
- Mini-PC form factor
- Ryzen AI Max+ Series processors
- Designed for local LLM development
- Targets AI researchers and developers

MARKET IMPLICATIONS:

The 128GB GPU memory allocation is a game-changer for local AI:

**Advantages:**
- Eliminates need for expensive discrete GPUs for many AI workloads
- Unified memory simplifies development (no CPU-GPU data transfers)
- Cost-effective alternative to NVIDIA workstation GPUs

**Limitations:**
- Still shares system memory (not dedicated VRAM)
- Bandwidth constraints vs. dedicated HBM/GDDR
- Thermal challenges in compact form factors

**Competitive Positioning:**

vs. Intel Core Ultra Series 3:
- AMD: 128GB allocatable to GPU (Max+ Series)
- Intel: 96GB maximum system memory
- AMD advantage for AI-intensive graphics workloads

vs. Apple Mac Studio:
- Apple: Up to 512GB unified memory (M3 Ultra)
- AMD: Up to 128GB allocatable
- Apple still leads in absolute capacity, but AMD offers better value

vs. NVIDIA Discrete GPUs:
- NVIDIA RTX 5090: 32GB GDDR (rumored)
- AMD Max+: 128GB shared system memory
- Trade-off: NVIDIA has bandwidth advantage, AMD has capacity advantage

STRATEGIC IMPLICATIONS:

For Phison:
- **Validation**: AMD's 128GB allocation confirms memory-intensive AI is mainstream
- **Complementary**: Even 128GB may be insufficient for largest workloads (opportunity for SSD offload)
- **Platform Diversity**: AMD's approach differs from Intel/Apple, creating varied optimization opportunities

For OEMs:
- Pressure to offer high-memory configurations (64GB+)
- AMD Max+ enables differentiation in AI workstation segment
- Cost considerations: 128GB DRAM configurations expensive amid shortages

For Developers:
- AMD Halo platform democratizes local AI development
- 128GB GPU allocation enables experimentation with larger models
- Still not enough for cutting-edge research (200B+ parameter models)

ANALYST PERSPECTIVE:

"AMD's 128GB GPU allocation is a clever workaround for the discrete GPU memory bottleneck," notes Jon Peddie Research. "However, it's still sharing system memory, which creates trade-offs. The real solution may be hybrid architectures combining high-capacity system memory with SSD-based offload for truly massive models."

The announcement also highlights the memory supply challenge: AMD's high-memory configurations will compete for the same constrained DRAM supply driving price increases across the industry.

---
Source: AMD CES 2026 Keynote
Contact: AMD Investor Relations
Published: January 7, 2026
